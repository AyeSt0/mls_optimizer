# -*- coding: utf-8 -*-
"""
MLS Optimizer — Patched (colmap v2)
Column mapping (0-based):
  col0: RU (optional)
  col1: EN
  col2: Speaker
  col3: EN-mixed (EN with inline zh/markers)  <-- seed column used by step 20
  col4: ZH_NEW (target)                       <-- all later steps operate here
This file is generated by ChatGPT to fix column layout and pipeline order.
"""

import argparse, json, os, re, time, threading, queue, math
import pandas as pd
import requests
from datetime import datetime

# Column mapping
COL_RU = 0
COL_EN = 1
COL_SPK = 2
COL_SEED = 3  # input seed (EN-mixed) chosen by step 20
COL_ZH  = 4  # output

SYSTEM_PROMPT = """You are a senior localization writer for an ADULT visual novel set in Sunville (阳光镇), mostly inside a COLLEGE (学院).
Output MUST be natural, colloquial Chinese for players.

GENERAL:
- Base literal meaning on EN; use RU for mood & sensual nuance when helpful.
- STRICTLY apply the glossary with LONGEST MATCH FIRST; never contradict it.
- Preserve placeholders/tags exactly: [like_this], {vars}, {{vars}}, <tags>.
- Keep brand/product names in Latin (Patreon, Instagram, Lovense).
- Use colloquial “你”; avoid stiff, bookish phrasing.
- You MAY restructure English syntax for natural Chinese (意合优先); merge or split clauses as needed.
- Use Chinese punctuation and spoken word order; avoid copying EN period-per-fragment habit.
- Output ONLY the final Chinese line (no quotes or explanations).
- DO NOT alter any Chinese characters that already appear in the input line; only translate the non-Chinese parts and blend naturally.

WORLD TERMS (PINNED):
- Sunville → 阳光镇
- College → 学院  (NEVER translate as 大学/大学院)
- Principal → 院长
- Steward → 管理员
- Doctor’s Office → 医务室
- Locker Rooms → 更衣室
- College Entrance → 学院正门

CAMPUS & TOWN LOCATION RULES (CRITICAL):
If the line is an ALL-CAPS/Title-like label and the SPEAKER is "string" (or looks like map/room/UI location), translate as a PLACE NAME, not a subject:
- SUBJECT + CLASS → “X教室”：Computer Class→计算机教室; Arts Class→美术教室
- Lone SUBJECT words (BIOLOGY/PHYSICS/ENGLISH/GEOGRAPHY/ALGEBRA) in this context → “X教室”
- ...’S OFFICE:
  - DOCTOR’S OFFICE → 医务室
  - STEWARD’S OFFICE → 管理员办公室
  - (others) “某某办公室” (keep role natural in CN)
- LOCKER (singular) → 储物柜区; LOCKER ROOMS (plural) → 更衣室
- GIRL’S/BOY’S CHANGING ROOM → 女生/男生更衣室
- BOYS/GIRLS TOILET(S) → 男厕 / 女厕（全局一致即可）
- GYM → 体育馆; POOL → 泳池; LIBRARY → 图书馆; ASSEMBLY HALL → 学院礼堂
- COLLEGE ENTRANCE → 学院正门
- TOWN → 镇上（地图/导航标签时更自然）

SPEAKER-AWARE TONE:
- Principal/Teacher/Librarian (incl. *_t thoughts) → formal, calm, precise; no slang.
- System/Operator/Post/Help/Hotel_staff/Secretary/Policeman → concise UI/service tone; no erotic flourish.
- Punk/Whore/Stripper/Showman → bolder, street tone; explicit but not gratuitous.
- Students/Girls/Actresses/Models/teen names → youthful, casual, flirty; explicit when context requires.

OBJECTIVES / TASK HINTS:
If the English is multiple short imperatives (Go to / Meet / Talk...), render as a natural Chinese flow:
- “前往肖恩家、见见他妈妈、和肖恩聊聊” 或 “去趟肖恩家，先见见他妈妈，再跟肖恩聊聊。”
Avoid stiff “认识他妈妈”。

DIALOGUE:
If it reads like human speech (pronouns, questions, interjections), make it colloquial; erotic when the scene needs it.
Moans/breathing (“嗯…/哈啊…/啊…”) natural but not overdone.
Be explicit but not clinical; don’t censor sexual content.
"""

def now():
    return datetime.now().strftime("%H:%M:%S")

def safe_get(d, *keys, default=None):
    cur = d
    for k in keys:
        if not isinstance(cur, dict): return default
        cur = cur.get(k)
        if cur is None: return default
    return cur

def load_settings(path):
    import yaml
    if not os.path.exists(path):
        return {}
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}

def pick_client(settings, provider_cli, rpm_cli, tpm_cli):
    provider = provider_cli or settings.get("provider") or "deepseek"
    llm = settings.get("llm", {})
    if provider == "deepseek":
        conf = llm.get("deepseek", {})
        base = conf.get("base_url") or "https://api.siliconflow.cn"
        key  = conf.get("api_key")
        model = safe_get(settings, "model", "deepseek", default=None) or conf.get("name") or "deepseek-ai/DeepSeek-V3.2-Exp"
        rpm = rpm_cli or safe_get(settings, "rate_limit","rpm", default=200) or 200
        tpm = tpm_cli or None
        return provider, base, key, model, rpm, tpm
    else:
        conf = llm.get("openai", {})
        base = conf.get("base_url") or "https://api.openai.com/v1"
        key  = conf.get("api_key")
        model = safe_get(settings, "model", "openai", default=None) or conf.get("name") or "gpt-4o-mini"
        rpm = rpm_cli or safe_get(settings, "rate_limit","rpm", default=120) or 120
        tpm = tpm_cli or None
        return "openai", base, key, model, rpm, tpm

def load_df(excel, sheet_index=None, sheet_name=None):
    if sheet_name is not None:
        df = pd.read_excel(excel, sheet_name=sheet_name)
    else:
        df = pd.read_excel(excel, sheet_name=sheet_index or 0)
    if df.shape[1] < 5:
        for _ in range(5-df.shape[1]):
            df[df.shape[1]] = ""
    return df

def build_prompt(row_en: str, row_ru: str, seed: str, speaker: str, gloss_snippets: str):
    # We must not alter any Chinese already in `seed`
    user = f"""SPEAKER: {speaker or ""}
EN: {row_en or ""}
RU: {row_ru or ""}
SEED (has Chinese/identifiers mixed; DO NOT change any existing Chinese or placeholders): {seed or ""}

GLOSSARY (apply longest-match-first, do not contradict):
{gloss_snippets}

Task: Produce a single Chinese line suitable for adult visual-novel gameplay, natural and colloquial,
respecting the campus/town rules above. Keep placeholders ([], {{}}, <>) intact. Output ONLY the final line.
"""
    return SYSTEM_PROMPT, user

def build_glossary_snippet(glossary_path, limit=300):
    if not glossary_path or not os.path.exists(glossary_path):
        return ""
    try:
        data = json.load(open(glossary_path, "r", encoding="utf-8"))
        if isinstance(data, dict):
            items = sorted(data.items(), key=lambda kv: len(kv[0]), reverse=True)[:limit]
        elif isinstance(data, list):
            tmp = []
            for it in data:
                if isinstance(it, dict) and "src" in it and "dst" in it:
                    tmp.append((it["src"], it["dst"]))
            items = sorted(tmp, key=lambda kv: len(kv[0]), reverse=True)[:limit]
        else:
            return ""
        return "\n".join([f"- {k} → {v}" for k,v in items])
    except Exception:
        return ""

def count_cn(s: str) -> int:
    if not isinstance(s, str): return 0
    return sum(1 for ch in s if '\u4e00' <= ch <= '\u9fff')

# Simple minute bucket rate-limiter with adaptive workers
class RateController:
    def __init__(self, rpm:int):
        self.rpm = max(1, rpm)
        self.lock = threading.Lock()
        self.bucket_reset = time.time() + 60
        self.used = 0

    def allow(self) -> float:
        with self.lock:
            now = time.time()
            if now >= self.bucket_reset:
                self.bucket_reset = now + 60
                self.used = 0
            if self.used < self.rpm:
                self.used += 1
                return 0.0
            # need to sleep until reset
            return max(0.0, self.bucket_reset - now)

def post_chat(base_url, api_key, model, sys_prompt, user_prompt):
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    url = base_url.rstrip("/") + "/v1/chat/completions"
    payload = {
        "model": model,
        "messages": [
            {"role": "system", "content": sys_prompt},
            {"role": "user",   "content": user_prompt},
        ],
        "temperature": 0.3,
    }
    r = requests.post(url, headers=headers, json=payload, timeout=60)
    if r.status_code == 429:
        raise RuntimeError("rate_limited")
    r.raise_for_status()
    j = r.json()
    return j["choices"][0]["message"]["content"].strip()

def save_excel(df, path):
    tmp = path + ".tmp.xlsx"
    df.to_excel(tmp, index=False)
    os.replace(tmp, path)

def main():
    ap = argparse.ArgumentParser(description="12_llm_translate with adaptive scaling (colmap v2)")
    ap.add_argument("--excel", required=True)
    ap.add_argument("--sheet-index", type=int, default=0)
    ap.add_argument("--sheet-name", default=None)
    ap.add_argument("--target-lang", default="zh-CN")
    ap.add_argument("--settings", default="config/settings.local.yaml")
    ap.add_argument("--provider", default=None, choices=[None, "deepseek", "openai"])
    ap.add_argument("--glossary", default=None)
    ap.add_argument("--autosave-every", type=int, default=300)
    ap.add_argument("--autosave-seconds", type=int, default=90)
    ap.add_argument("--wal-file", default="artifacts/translate.wal.jsonl")
    ap.add_argument("--wal-every", type=int, default=10)
    ap.add_argument("--show-lines", action="store_true")
    ap.add_argument("--max-chars", type=int, default=160)
    ap.add_argument("--rpm", type=int, default=None)
    ap.add_argument("--tpm-max", type=int, default=None)  # reserved, not using actual token count here
    ap.add_argument("--workers", type=int, default=8)
    ap.add_argument("--min-workers", type=int, default=2)
    ap.add_argument("--max-workers", type=int, default=32)
    ap.add_argument("--row-range", default=None, help="e.g. 100-500")
    ap.add_argument("--speaker-filter", default=None, help="e.g. student_* ; glob-style")
    ap.add_argument("--overwrite", action="store_true", help="translate even if col4 already has content")
    ap.add_argument("--dry-run", action="store_true")
    ap.add_argument("--out", default=None)
    args = ap.parse_args()

    settings = load_settings(args.settings)
    provider, base_url, api_key, model, rpm_init, _tpm = pick_client(settings, args.provider, args.rpm, args.tpm_max)
    if not api_key:
        print("[ERROR] Missing API key (check config/settings.local.yaml).")
        sys.exit(1)

    df = load_df(args.excel, sheet_index=args.sheet_index, sheet_name=args.sheet_name)

    # Range / speaker filters
    start, end = 0, len(df)
    if args.row_range:
        m = re.match(r"(\d+)-(\d+)", args.row_range.strip())
        if m:
            start, end = int(m.group(1)), int(m.group(2))
            start = max(0, start); end = min(len(df), end)

    import fnmatch
    spk_pat = args.speaker_filter.strip() if args.speaker_filter else None

    # build glossary snippet
    gloss_snip = build_glossary_snippet(args.glossary, limit=300)

    # WAL file
    os.makedirs(os.path.dirname(args.wal_file), exist_ok=True)
    wal = open(args.wal_file, "a", encoding="utf-8")

    # Shared structures
    q = queue.Queue()
    lock = threading.Lock()
    updated = 0
    last_save = time.time()
    save_every = max(1, args.autosave_every)
    wal_every = max(1, args.wal_every)
    progress = 0
    rc = RateController(rpm_init)

    # enqueue tasks
    for idx in range(start, end):
        row = df.iloc[idx]
        if spk_pat and not fnmatch.fnmatch(str(row.iloc[COL_SPK]), spk_pat):
            continue
        have = str(row.iloc[COL_ZH]) if not pd.isna(row.iloc[COL_ZH]) else ""
        if have and not args.overwrite:
            continue
        # input seed from col3
        seed = str(row.iloc[COL_SEED]) if not pd.isna(row.iloc[COL_SEED]) else ""
        en   = str(row.iloc[COL_EN]) if not pd.isna(row.iloc[COL_EN]) else ""
        ru   = str(row.iloc[COL_RU]) if not pd.isna(row.iloc[COL_RU]) else ""
        q.put((idx, seed, en, ru, str(row.iloc[COL_SPK])))

    total = q.qsize()
    if total == 0:
        outp = args.out or args.excel.replace(".xlsx", f".{args.target_lang}.llm.xlsx")
        save_excel(df, outp)
        print(f"[OK] Done. Output -> {outp}")
        wal.close()
        return

    def worker():
        nonlocal updated, progress
        while True:
            try:
                item = q.get_nowait()
            except queue.Empty:
                return
            idx, seed, en, ru, spk = item
            if args.dry_run:
                with lock:
                    progress += 1
                    if args.show_lines:
                        print(f"[{now()}] DRY idx={idx} spk={spk}\n  SEED: {seed}\n  EN: {en}\n  RU: {ru}")
                q.task_done()
                continue

            sys_p, user_p = build_prompt(en, ru, seed, spk, gloss_snip)

            # rate limit wait
            delay = rc.allow()
            if delay > 0: time.sleep(delay)

            ok = False
            backoff = 1.0
            for attempt in range(5):
                try:
                    out = post_chat(base_url, api_key, model, sys_p, user_p)
                    ok = True
                    break
                except RuntimeError as e:
                    if "rate_limited" in str(e):
                        time.sleep(backoff)
                        backoff = min(10.0, backoff*1.8)
                    else:
                        time.sleep(backoff)
                        backoff = min(6.0, backoff*1.6)
                except Exception:
                    time.sleep(backoff)
                    backoff = min(6.0, backoff*1.6)
            with lock:
                progress += 1
                if ok:
                    df.iat[idx, COL_ZH] = out
                    wal.write(json.dumps({"row": idx, "spk": spk, "out": out}, ensure_ascii=False) + "\n")
                    if progress % wal_every == 0:
                        wal.flush()
                    updated += 1
                    if args.show_lines:
                        print(f"[{now()}] idx={idx} spk={spk}\n  OUT: {out}")
                else:
                    # leave empty; will be retried on next run
                    if args.show_lines:
                        print(f"[{now()}] idx={idx} FAILED")

            # periodic autosave
            if (progress % save_every == 0) or (time.time()-last_save > args.autosave_seconds):
                save_excel(df, args.out or args.excel.replace(".xlsx", f".{args.target_lang}.llm.xlsx"))

            q.task_done()

    # spawn workers
    threads = []
    W = max(args.min_workers, min(args.workers, args.max_workers))
    for _ in range(W):
        t = threading.Thread(target=worker, daemon=True); t.start(); threads.append(t)
    [t.join() for t in threads]

    outp = args.out or args.excel.replace(".xlsx", f".{args.target_lang}.llm.xlsx")
    save_excel(df, outp)
    wal.flush(); wal.close()
    print(f"[OK] Finished. total={total} updated={updated} Output -> {outp}")

if __name__ == "__main__":
    main()
